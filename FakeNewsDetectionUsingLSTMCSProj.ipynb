{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6aCV0Z35q7F"
      },
      "source": [
        "Importing primary dependencies for data fetch and cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRjajrhYKiBa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from pandas import read_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-FillisipV"
      },
      "source": [
        "Various constants and data fetch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2hohf4zZVXT"
      },
      "outputs": [],
      "source": [
        "max_features=3600\n",
        "max_len=1024\n",
        "test_prop=0.3\n",
        "epoch_count=20\n",
        "batch_size=2048\n",
        "fake=read_csv('https://raw.githubusercontent.com/MobiusYeeitus/CSProj/master/datasets/set1/fake.csv')\n",
        "real=read_csv('https://raw.githubusercontent.com/MobiusYeeitus/CSProj/master/datasets/set1/true.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5h7OH9QaqG-"
      },
      "outputs": [],
      "source": [
        "#fake.sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ-mn7ScauJG"
      },
      "outputs": [],
      "source": [
        "#real.sample(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISnhJyPWsMpr"
      },
      "source": [
        "Compressed every cleanup job into the *clean_csv* function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAmsPhuDcxXr"
      },
      "outputs": [],
      "source": [
        "def clean_string(string): #function to clean a string | to be used in clean_csv\n",
        "    string=string.lower() #convert string to lowercase\n",
        "    string=re.sub('\\n|\\r|\\t','',string) #cleaning of whitespaces\n",
        "    string=re.sub(r'[^\\w\\s]+','',string) #cleaning of symbols\n",
        "    return string\n",
        "def clean_csv(df,identity): #cleaning the CSV file\n",
        "    print('Cleaning CSV.')\n",
        "    df=df.dropna() #drop all tuples with empty attributes\n",
        "    length=[]\n",
        "    [length.append(len(str(text))) for text in df[\"text\"]] #calculate length of an article\n",
        "    df['length'] = length #saves the length of the artivle in a new column\n",
        "    df = df.drop(df['text'][df['length'] < 120].index, axis = 0) #drop all tuples with less than 120 letters\n",
        "    df['text']=df['title']+\" \"+df['text'] #append text to title\n",
        "    vfunc=np.vectorize(clean_string) #vectorize th clean_string function for use in pandas df\n",
        "    df['text']=vfunc(df['text']) #apply the vectorized function to further clean the data\n",
        "    df['identity']=identity #add the identity (T/F) or (0/1) in a new attribute to the data\n",
        "    df.reset_index() #reset all indexes of the dataset\n",
        "    print('Cleaning completed.')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pOY72SkdAs2",
        "outputId": "e9098fae-a87b-4bff-d2fa-335e5a334a14"
      },
      "outputs": [],
      "source": [
        "fake=clean_csv(fake,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-iLsEjEgiTH"
      },
      "outputs": [],
      "source": [
        "#fake.sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b4ZU2MBiqFN"
      },
      "outputs": [],
      "source": [
        "real=clean_csv(real,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_GaUEAmqNK9"
      },
      "outputs": [],
      "source": [
        "#real.sample(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXgRG0KMsAAq"
      },
      "source": [
        "Dropping all unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzvB2FiSqT1g"
      },
      "outputs": [],
      "source": [
        "fake=fake[['text','identity']]\n",
        "real=real[['text','identity']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWQ6U5g8sv-T"
      },
      "outputs": [],
      "source": [
        "#fake.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KBiiWP3xfX1"
      },
      "outputs": [],
      "source": [
        "data=pd.concat([real,fake])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnnp3zsoxlXe"
      },
      "outputs": [],
      "source": [
        "data.sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv('datasets/output/cache/experimental-branch-cache/ds1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExKTZNml5050"
      },
      "source": [
        "Importing dependencies for ANN and Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwJ6aopd2Vpl"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Conv1D,MaxPool1D,Dropout,GRU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duo7OpvF6Zq3"
      },
      "source": [
        "Tokenizing the dataset for use in the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNecmkTH6CY2"
      },
      "outputs": [],
      "source": [
        "def tokenize_df(df,max_features): #tokenize the df using keras tokenizer\n",
        "        print('Tokenizing DF.')\n",
        "        tokenizer=Tokenizer(num_words=max_features,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',split =' ') #filters is redundant, but still keeping if I missed any symbols previously\n",
        "        tokenizer.fit_on_texts(texts=df['text']) #fit\n",
        "        X = tokenizer.texts_to_sequences(texts=df['text'])\n",
        "        X = pad_sequences(sequences=X,maxlen=max_len,padding='pre') #padding the set of words\n",
        "        Y = df['identity'].values #identities (0/1)\n",
        "        V=tokenizer.word_index #vocabulary\n",
        "        print('Tokenized DF.')\n",
        "        return X,Y,V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBaQSCHt6Idv",
        "outputId": "9dfe144f-fdd2-42bf-c287-4d0a4b3a5c23"
      },
      "outputs": [],
      "source": [
        "X,Y,V=tokenize_df(data,max_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyJBuhS6mPJ"
      },
      "source": [
        "Creating the model and compiling it to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Oc9EBxT3EHr"
      },
      "outputs": [],
      "source": [
        "def create_lstm_model(max_features): #creating the internal structure of the simple LSTM model\n",
        "        print('Creating LSTM model.')\n",
        "        lstm_model=Sequential(name='Sierra')\n",
        "        lstm_model.add(layer=Embedding(input_dim=128,output_dim=128,name='Alpha'))\n",
        "        lstm_model.add(layer=LSTM(units=128,name='Lima'))\n",
        "        lstm_model.add(layer=Dense(1,activation='sigmoid',name ='Omega'))\n",
        "        print('Model creation completed.')\n",
        "        lstm_model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "        print('Model compiled.')\n",
        "        return lstm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veGVczge3Gv7",
        "outputId": "bc9f3675-9339-4c7f-e950-1387ee166290"
      },
      "outputs": [],
      "source": [
        "lstm_model=create_lstm_model(max_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZE9GRYJ3LOm"
      },
      "outputs": [],
      "source": [
        "X_train,X_text,Y_train,Y_test=train_test_split(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "jEMmEicn3Oo7",
        "outputId": "95f56879-2f75-4b29-f5ac-3762b69518cc"
      },
      "outputs": [],
      "source": [
        "lstm_model.fit(X_train,Y_train,batch_size=batch_size,epochs=epoch_count,verbose=1,validation_split=test_prop,shuffle=1,use_multiprocessing=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YGvPhYz3PrD",
        "outputId": "f559ae66-1e76-4373-c091-1c941e3898c6"
      },
      "outputs": [],
      "source": [
        "Y_pred = (lstm_model.predict(X_text) >=0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXqn5Mww3bij",
        "outputId": "7107a74c-f578-44f2-cbeb-96e9f461fca7"
      },
      "outputs": [],
      "source": [
        "accuracy_score(Y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muWVKMp43c8k",
        "outputId": "d17d83e2-dbf7-463e-e0e6-1666ead92074"
      },
      "outputs": [],
      "source": [
        "print(classification_report(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUwYqLuP3eN3"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', split = ' ')\n",
        "x = [\"Vladimir Putin and Russia are not the aggressors in this conflict, and that the U.S. orchestrated the 2022 invasion of Ukraine.\"]\n",
        "x = tokenizer.texts_to_sequences(x)\n",
        "x = pad_sequences(x, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2rpKL4A3j9j",
        "outputId": "198ee15d-9e7f-4455-a15c-c45be685aee5"
      },
      "outputs": [],
      "source": [
        "l = [(lstm_model.predict(x) >=0.5).astype(int)]\n",
        "if l[0][0]==0:\n",
        "  print('FAKE')\n",
        "else:\n",
        "  print('REAL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WQDuweI4QIo",
        "outputId": "698aaefe-9fd6-435f-bba0-50e28826982c"
      },
      "outputs": [],
      "source": [
        "lstm_model.save('models/new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "cAbExGLr3nmb",
        "outputId": "3600df5e-e9d5-4172-c2d0-8daa15ef598f"
      },
      "outputs": [],
      "source": [
        "nmod=tf.keras.saving.load_model('models/new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak6X3Qzb3qHz",
        "outputId": "b0edcbec-2ec3-4b0e-fecd-e6fb8344098a"
      },
      "outputs": [],
      "source": [
        "y_pred = (nmod.predict(X_text) >=0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsiixWvy4Kjj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
